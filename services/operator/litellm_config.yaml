# LiteLLM Proxy Configuration
# Translates Anthropic API requests to OpenAI-compatible API format
# This allows Claude Code to work with any OpenAI-compatible model

model_list:
  # Map claude-sonnet model to the configured OpenAI model
  - model_name: claude-sonnet-4-20250514
    litellm_params:
      model: openai/${OPENAI_MODEL:-gpt-4o}
      api_base: ${OPENAI_BASE_URL:-https://api.openai.com/v1}
      api_key: ${OPENAI_API_KEY}

  # Also map claude-3-5-sonnet for compatibility
  - model_name: claude-3-5-sonnet-20241022
    litellm_params:
      model: openai/${OPENAI_MODEL:-gpt-4o}
      api_base: ${OPENAI_BASE_URL:-https://api.openai.com/v1}
      api_key: ${OPENAI_API_KEY}

  # Map any claude model request to the configured model
  - model_name: claude-*
    litellm_params:
      model: openai/${OPENAI_MODEL:-gpt-4o}
      api_base: ${OPENAI_BASE_URL:-https://api.openai.com/v1}
      api_key: ${OPENAI_API_KEY}

litellm_settings:
  # Drop any params not supported by target model
  drop_params: true
  # Enable request/response logging for debugging
  set_verbose: false

general_settings:
  # Master key for proxy authentication
  master_key: ${LITELLM_MASTER_KEY:-sk-litellm-operator}
