# Docker Compose configuration for Tale Services
# This file defines the services needed to run the Tale platform

services:
  # ============================================================================
  # Tale DB (TimescaleDB)
  # ============================================================================
  db:
    # Build configuration
    build:
      context: .
      dockerfile: services/db/Dockerfile

    # Container name
    container_name: tale-db

    # Port mapping: host:container
    # Access PostgreSQL at localhost:5432
    ports:
      - '5432:5432'

    # Volume mounts
    # Persist database data
    volumes:
      # PostgreSQL data directory
      - db-data:/var/lib/postgresql/data
      # Backup directory (optional)
      - db-backup:/var/lib/postgresql/backup

    # Environment file
    # Create a .env file in the project root with your database credentials
    env_file:
      - .env

    # Restart policy
    # Automatically restart the container if it crashes
    restart: unless-stopped

    # Health check
    # Docker will check if the database is ready
    healthcheck:
      test:
        [
          'CMD-SHELL',
          'pg_isready -U ${POSTGRES_USER:-tale} -d ${POSTGRES_DB:-tale}',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    # Resource limits (optional, adjust based on your needs)
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '4'
    #       memory: 8G
    #     reservations:
    #       cpus: '2'
    #       memory: 4G

    # Logging configuration
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

    # Networks
    networks:
      - internal

  # ============================================================================
  # Tale Graph DB (Kuzu)
  # ============================================================================
  # Stateful service - Kuzu requires exclusive file lock, cannot run two instances
  graph-db:
    # Build from local Dockerfile
    build:
      context: ./services/graph-db
      dockerfile: Dockerfile

    # Container name - stateful service like db
    container_name: tale-graph-db

    # No port mapping needed - only accessed by other services (rag)
    # internally via http://graph-db:8000

    # Volume mounts
    # Persist graph database data
    volumes:
      - graph-db-data:/data

    # Restart policy
    # Automatically restart the container if it crashes
    restart: unless-stopped

    # Health check - optimized for faster blue-green deployment
    # Docker will check if the service is healthy
    # Note: Using Python since curl is not available in python:3.11-slim
    healthcheck:
      test: ['CMD', 'python', '-c', 'import urllib.request; urllib.request.urlopen("http://localhost:8000/health")']
      interval: 5s
      timeout: 3s
      retries: 2
      start_period: 10s

    # Logging configuration
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

    # Networks
    networks:
      - internal

  # ============================================================================
  # Tale Crawler (Crawl4AI)
  # ============================================================================
  # Stateless service - no container_name for blue-green deployment
  crawler:
    # Build configuration
    build:
      context: .
      dockerfile: services/crawler/Dockerfile

    # Port mapping: host:container (for development)
    # Access Crawler API at localhost:8002
    ports:
      - '8002:8002'

    # Environment file
    # Create a .env file in the project root with your configuration
    env_file:
      - .env

    # Restart policy
    # Automatically restart the container if it crashes
    restart: unless-stopped

    # Health check - optimized for faster blue-green deployment
    # Docker will check if the service is healthy
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:8002/health']
      interval: 5s
      timeout: 3s
      retries: 2
      start_period: 40s

    # Resource limits (optional, adjust based on your needs)
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '2'
    #       memory: 4G
    #     reservations:
    #       cpus: '1'
    #       memory: 2G

    # Logging configuration
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

    # Networks
    networks:
      - internal

  # ============================================================================
  # Tale RAG (Cognee)
  # ============================================================================
  # Stateless service - no container_name for blue-green deployment
  rag:
    # Build configuration
    build:
      context: .
      dockerfile: services/rag/Dockerfile

    # Port mapping: host:container (for development)
    # Access RAG API at localhost:8001
    ports:
      - '8001:8001'

    # Volume mounts
    # Persist cognee data
    volumes:
      # Cognee data directory
      - rag-data:/app/data

    # Environment file
    # Create a .env file in the project root with your API keys
    env_file:
      - .env

    # Environment variables
    environment:
      # Chunk size for document processing
      # Smaller chunks (512) reduce LLM output size for knowledge graph extraction
      - RAG_CHUNK_SIZE=512
      - RAG_CHUNK_OVERLAP=50

    # Restart policy
    # Automatically restart the container if it crashes
    restart: unless-stopped

    # Health check - optimized for faster blue-green deployment
    # Docker will check if the service is healthy
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:8001/health']
      interval: 5s
      timeout: 3s
      retries: 2
      start_period: 40s

    # Dependencies
    # Wait for database and graph DB to be ready
    depends_on:
      - db
      - graph-db

    # Resource limits (optional, adjust based on your needs)
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '2'
    #       memory: 4G
    #     reservations:
    #       cpus: '1'
    #       memory: 2G

    # Logging configuration
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

    # Networks
    networks:
      - internal

  # ============================================================================
  # Tale Platform (Next.js + Convex)
  # ============================================================================
  # Stateless service - no container_name for blue-green deployment
  platform:
    # Build configuration
    build:
      context: .
      dockerfile: services/platform/Dockerfile

    # No port mapping needed - accessed via proxy at https://tale.local (or your domain)
    # internally via http://platform:3000

    # Volume mounts
    # Persist Convex local data
    volumes:
      # Convex local backend data
      - platform-convex-data:/app/convex-data
      # Mount Caddy's CA certificates for trusting self-signed certificates (development only)
      - caddy-data:/caddy-data:ro

    # Environment file
    # Create a .env file in the project root with your configuration
    env_file:
      - .env

    # Environment variables
    environment:
      # CA cert path for self-signed mode - entrypoint script checks if file exists
      # With Let's Encrypt, this file doesn't exist and is safely ignored
      # The entrypoint will set NODE_EXTRA_CA_CERTS only if the file exists
      - CADDY_CA_CERT_PATH=/caddy-data/caddy/pki/authorities/local/root.crt

    # Restart policy
    # Automatically restart the container if it crashes
    restart: unless-stopped

    # Health check - optimized for faster blue-green deployment
    # Docker will check if the service is healthy (both Next.js and Convex)
    healthcheck:
      test:
        [
          'CMD-SHELL',
          'curl -sf http://localhost:3000/api/health && curl -sf http://localhost:3210/version',
        ]
      interval: 5s
      timeout: 3s
      retries: 3
      start_period: 120s

    # Dependencies
    # Wait for backend services to be ready
    depends_on:
      - db
      - graph-db
      - rag
      - crawler
      - search

    # Resource limits (optional, adjust based on your needs)
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '2'
    #       memory: 4G
    #     reservations:
    #       cpus: '1'
    #       memory: 2G

    # Logging configuration
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

    # Networks
    networks:
      - internal

  # ============================================================================
  # Tale Search (SearXNG) - Self-hosted Meta Search Engine
  # ============================================================================
  # Stateless service - no container_name for blue-green deployment
  search:
    # Build configuration
    build:
      context: .
      dockerfile: services/search/Dockerfile

    # Port mapping: host:container (for development)
    # Access SearXNG at localhost:8003
    ports:
      - '8003:8080'

    # Environment file
    env_file:
      - .env

    # Restart policy
    restart: unless-stopped

    # Health check - optimized for faster blue-green deployment
    healthcheck:
      test:
        [
          'CMD',
          'wget',
          '--no-verbose',
          '--tries=1',
          '--spider',
          '--header=X-Real-IP: 127.0.0.1',
          'http://localhost:8080/healthz',
        ]
      interval: 5s
      timeout: 3s
      retries: 2
      start_period: 30s

    # Logging configuration
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

    # Networks
    networks:
      - internal

  # ============================================================================
  # Tale Proxy (Caddy)
  # ============================================================================
  # Single entry point for all traffic (both local dev and production)
  # Always serves over HTTPS with configurable certificate source.
  #
  # TLS Configuration (set in .env):
  #   TLS_MODE=selfsigned   - Self-signed certs (default, for development)
  #   TLS_MODE=letsencrypt  - Let's Encrypt certs (for production)
  #
  # For local development:
  #   - Run: docker compose up
  #   - Access: https://tale.local (self-signed cert, browser warning expected)
  #   - To trust certs: docker exec tale-proxy caddy trust
  #
  # For production with HTTPS:
  #   - Set HOST=yourdomain.com and SITE_URL=https://yourdomain.com in .env
  #   - Set TLS_MODE=letsencrypt
  #   - Access: https://yourdomain.com (trusted Let's Encrypt cert)
  #
  proxy:
    # Build configuration
    build:
      context: .
      dockerfile: services/proxy/Dockerfile

    # Container name
    container_name: tale-proxy

    # Port mapping: host:container
    # Access the platform via HTTP (80) or HTTPS (443)
    ports:
      - '80:80'
      - '443:443'

    # Volume mounts
    # Persist Caddy data (certificates, etc.)
    volumes:
      # Caddy data directory for certificates and configuration
      - caddy-data:/data
      # Caddy config directory
      - caddy-config:/config

    # Environment file
    # Create a .env file in the project root with your domain configuration
    env_file:
      - .env

    # Restart policy
    # Automatically restart the container if it crashes
    restart: unless-stopped

    # Health check
    # Docker will check if the proxy is healthy via /health endpoint on HTTP
    # Using HTTP on localhost avoids SSL/IPv6 issues for internal health checks
    healthcheck:
      test:
        [
          'CMD',
          'wget',
          '--no-verbose',
          '--tries=1',
          '--spider',
          'http://127.0.0.1:80/health',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

    # Note: We removed depends_on for platform to avoid circular dependency
    # when platform uses links/extra_hosts to reach localhost via proxy.
    # Caddy handles upstream unavailability gracefully.

    # Logging configuration
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

    # Networks
    networks:
      internal:
        # Hairpin NAT resolution via network alias
        # This allows containers to resolve HOST to the proxy container
        # via Docker's internal DNS, solving the hairpin NAT issue.
        # Use app.localhost (or another real hostname) instead of localhost
        # because localhost is always in /etc/hosts and can't be overridden.
        aliases:
          - ${HOST:-tale.local}

# ============================================================================
# Volumes
# ============================================================================
volumes:
  # Tale DB persistent storage
  db-data:
    driver: local
    # Optional: Use named volume with specific driver options
    # driver_opts:
    #   type: none
    #   o: bind
    #   device: /path/to/db/data

  # Tale DB backup storage
  db-backup:
    driver: local

  # Persistent storage for graph database data (Kuzu)
  graph-db-data:
    driver: local

  # Persistent storage for RAG service data
  rag-data:
    driver: local

  # Persistent storage for Platform Convex local backend
  platform-convex-data:
    driver: local

  # Persistent storage for Caddy proxy data (certificates, etc.)
  caddy-data:
    driver: local

  # Persistent storage for Caddy proxy configuration
  caddy-config:
    driver: local

# ============================================================================
# Networks
# ============================================================================
networks:
  # Internal network for Tale services
  internal:
    driver: bridge
